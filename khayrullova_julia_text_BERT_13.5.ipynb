{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Описание-проекта\" data-toc-modified-id=\"Описание-проекта-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Описание проекта</a></span></li><li><span><a href=\"#Библиотеки\" data-toc-modified-id=\"Библиотеки-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Библиотеки</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#toxic-BERT\" data-toc-modified-id=\"toxic-BERT-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>toxic-BERT</a></span></li><li><span><a href=\"#Токенизация\" data-toc-modified-id=\"Токенизация-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Токенизация</a></span></li><li><span><a href=\"#Cuda\" data-toc-modified-id=\"Cuda-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Cuda</a></span></li><li><span><a href=\"#Эмбеддинги\" data-toc-modified-id=\"Эмбеддинги-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Эмбеддинги</a></span></li><li><span><a href=\"#Split\" data-toc-modified-id=\"Split-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Split</a></span></li><li><span><a href=\"#(Up&amp;)Downsampling\" data-toc-modified-id=\"(Up&amp;)Downsampling-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>(Up&amp;)Downsampling</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#SVC\" data-toc-modified-id=\"SVC-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>SVC</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Проверка-на-адекватность\" data-toc-modified-id=\"Проверка-на-адекватность-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Проверка на адекватность</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT\n",
    "\n",
    "~~(DistilBERT)~~\n",
    "\n",
    "(toxic BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Алгоритм**\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделать выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import notebook\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "import gc\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'toxic_comments.csv'\n",
    "pth1 = '/datasets/'\n",
    "pth2 = ''\n",
    "\n",
    "if os.path.exists(pth1+fname):\n",
    "    df = pd.read_csv(pth1+fname)\n",
    "elif os.path.exists(pth2+fname):\n",
    "    df = pd.read_csv(pth2+fname)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean        394.073221\n",
       "std         590.720282\n",
       "min           6.000000\n",
       "25%          96.000000\n",
       "50%         205.000000\n",
       "75%         435.000000\n",
       "max        5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df.text.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>And \\n\\nPaganism\\n\\nSouthgate, who has a degre...</td>\n",
       "      <td>0</td>\n",
       "      <td>4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>\"\\n\\n(Ivo Banac)...A bit of nonteleological hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>ii CAN STILL POST WITH THIS COMPUTER...I SAID ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>do go fuck off bastard\\nDo Yyou Have a life?\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>4969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AI...</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156437</th>\n",
       "      <td>HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGO...</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157861</th>\n",
       "      <td>\"\\n\\n Made in the USA? http://rexcurry.net/wik...</td>\n",
       "      <td>0</td>\n",
       "      <td>4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158572</th>\n",
       "      <td>Originally born in OHIO,and raised on a yuppie...</td>\n",
       "      <td>0</td>\n",
       "      <td>4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158970</th>\n",
       "      <td>Hi Wikipedia!!Hi Wikipedia!!Hi Wikipedia!!Hi W...</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  length\n",
       "1184    And \\n\\nPaganism\\n\\nSouthgate, who has a degre...      0    4908\n",
       "2420    FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT ...      1    4999\n",
       "3954    \"\\n\\n(Ivo Banac)...A bit of nonteleological hi...      0    4946\n",
       "4174    ii CAN STILL POST WITH THIS COMPUTER...I SAID ...      1    5000\n",
       "4712    do go fuck off bastard\\nDo Yyou Have a life?\\n...      1    4969\n",
       "...                                                   ...    ...     ...\n",
       "156032  AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AI...      1    5000\n",
       "156437  HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGO...      1    5000\n",
       "157861  \"\\n\\n Made in the USA? http://rexcurry.net/wik...      0    4912\n",
       "158572  Originally born in OHIO,and raised on a yuppie...      0    4976\n",
       "158970  Hi Wikipedia!!Hi Wikipedia!!Hi Wikipedia!!Hi W...      0    5000\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('length > 4900')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, что с очень длинными текстами нет проблемы (но среди них как раз много токсичных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      " 2   length  159571 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    1\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.toxic\n",
    "target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### toxic-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For DistilBERT:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "# ## For BERT instead of distilBERT:\n",
    "# #model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# # Load pretrained model/tokenizer\n",
    "# tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "# model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"unitary/toxic-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.08.2022 21:38:08'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime(\"%d.%m.%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.08.2022 21:40:50'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime(\"%d.%m.%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3050 Laptop GPU', major=8, minor=6, total_memory=4095MB, multi_processor_count=16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "# embeddings = torch.zeros(1,768, device=device)\n",
    "embeddings = torch.zeros(1,6, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80914f13a1784756bd6c2542552ea73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "model.eval()\n",
    "model.to(device)\n",
    "for i in notebook.tqdm(range(\n",
    "#     1\n",
    "    int(np.ceil(padded.shape[0] / batch_size))\n",
    ")):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():            \n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "#         embeddings = torch.cat((embeddings, batch_embeddings[0][:,0,:]), 0)   # :,0,: - только CLS токен\n",
    "#         print(batch_embeddings.logits.shape)\n",
    "        embeddings = torch.cat((embeddings, batch_embeddings.logits), 0)\n",
    "        \n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159572, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-7.1086, -9.1583, -8.6032, -9.1510, -8.6369, -8.9100]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1086, -9.1583, -8.6032, -9.1510, -8.6369, -8.9100],\n",
       "        [-7.3556, -9.0493, -8.6204, -9.0126, -8.6399, -8.9054]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings[1:,:]\n",
    "embeddings[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159571, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = embeddings.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.10855  , -9.158272 , -8.6032095, -9.150958 , -8.636943 ,\n",
       "        -8.910042 ],\n",
       "       [-7.355632 , -9.049333 , -8.620355 , -9.012584 , -8.639869 ,\n",
       "        -8.905448 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, \n",
    "    test_size=0.85, random_state=1734, \n",
    "    stratify=target,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10169208272404429"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167654604972132"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.reset_index(drop=True, inplace=True)\n",
    "target_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     1\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    1\n",
       "14    0\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Up&)Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.DataFrame(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target_train == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345678)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13114224137931035\n"
     ]
    }
   ],
   "source": [
    "# features_train, target_train = upsample(features_train, target_train, 2)\n",
    "features_train, target_train = downsample(features_train, target_train, 0.75)\n",
    "\n",
    "print(target_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:41:23'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "[LibLinear]Wall time: 2.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=LogisticRegression(class_weight='balanced', max_iter=300,\n",
       "                                          random_state=245982, tol=5e-05,\n",
       "                                          verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([0.47   , 0.49125, 0.5125 , 0.53375, 0.555  , 0.57625, 0.5975 ,\n",
       "       0.61875, 0.64   ]),\n",
       "                         'fit_intercept': [True], 'penalty': ['l2'],\n",
       "                         'solver': ['lbfgs', 'liblinear']},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_model = LogisticRegression(random_state=245982, max_iter=300, class_weight='balanced', verbose=2,\n",
    "                                  tol=0.00005)\n",
    "\n",
    "params = dict(C=np.linspace(0.47, 0.64, 9), \n",
    "              penalty=['l2'],   #,'l1'\n",
    "              solver=['lbfgs', 'liblinear' ],   # 'newton-cg', 'saga', 'sag'\n",
    "              fit_intercept=[True]\n",
    "             )\n",
    "grid = GridSearchCV(log_reg_model, params, verbose=2, scoring='f1', cv=4, n_jobs=-1)\n",
    "grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5549999999999999, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'} \n",
      "\n",
      "0.92946749627566 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_,'\\n')\n",
    "print(grid.best_score_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:41:25'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:43:56'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6c5afd44f54879b2d77f51eb248b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.9467455621\n",
      "bestIteration = 4\n",
      "\n",
      "0:\tloss: 0.9467456\tbest: 0.9467456 (0)\ttotal: 678ms\tremaining: 31.8s\n",
      "\n",
      "bestTest = 0.9485148515\n",
      "bestIteration = 3\n",
      "\n",
      "\n",
      "bestTest = 0.9475766568\n",
      "bestIteration = 2\n",
      "\n",
      "\n",
      "bestTest = 0.9470529471\n",
      "bestIteration = 28\n",
      "\n",
      "\n",
      "bestTest = 0.9465346535\n",
      "bestIteration = 6\n",
      "\n",
      "\n",
      "bestTest = 0.9475766568\n",
      "bestIteration = 7\n",
      "\n",
      "\n",
      "bestTest = 0.9464285714\n",
      "bestIteration = 11\n",
      "\n",
      "\n",
      "bestTest = 0.9464285714\n",
      "bestIteration = 11\n",
      "\n",
      "\n",
      "bestTest = 0.9465346535\n",
      "bestIteration = 7\n",
      "\n",
      "\n",
      "bestTest = 0.9475766568\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9462151394\n",
      "bestIteration = 21\n",
      "\n",
      "10:\tloss: 0.9462151\tbest: 0.9485149 (1)\ttotal: 4.92s\tremaining: 16.6s\n",
      "\n",
      "bestTest = 0.9438423645\n",
      "bestIteration = 6\n",
      "\n",
      "\n",
      "bestTest = 0.9452736318\n",
      "bestIteration = 32\n",
      "\n",
      "\n",
      "bestTest = 0.9474727453\n",
      "bestIteration = 9\n",
      "\n",
      "\n",
      "bestTest = 0.9474727453\n",
      "bestIteration = 9\n",
      "\n",
      "\n",
      "bestTest = 0.9473684211\n",
      "bestIteration = 12\n",
      "\n",
      "\n",
      "bestTest = 0.9453823237\n",
      "bestIteration = 11\n",
      "\n",
      "\n",
      "bestTest = 0.9454905847\n",
      "bestIteration = 13\n",
      "\n",
      "\n",
      "bestTest = 0.9433962264\n",
      "bestIteration = 0\n",
      "\n",
      "\n",
      "bestTest = 0.9465346535\n",
      "bestIteration = 16\n",
      "\n",
      "\n",
      "bestTest = 0.9473684211\n",
      "bestIteration = 15\n",
      "\n",
      "20:\tloss: 0.9473684\tbest: 0.9485149 (1)\ttotal: 9.32s\tremaining: 12s\n",
      "\n",
      "bestTest = 0.9491525424\n",
      "bestIteration = 34\n",
      "\n",
      "\n",
      "bestTest = 0.9482071713\n",
      "bestIteration = 74\n",
      "\n",
      "\n",
      "bestTest = 0.9474727453\n",
      "bestIteration = 34\n",
      "\n",
      "\n",
      "bestTest = 0.9444444444\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9482071713\n",
      "bestIteration = 15\n",
      "\n",
      "\n",
      "bestTest = 0.9446640316\n",
      "bestIteration = 2\n",
      "\n",
      "\n",
      "bestTest = 0.9483101392\n",
      "bestIteration = 19\n",
      "\n",
      "\n",
      "bestTest = 0.9467455621\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9467455621\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9512437811\n",
      "bestIteration = 89\n",
      "\n",
      "30:\tloss: 0.9512438\tbest: 0.9512438 (30)\ttotal: 13.9s\tremaining: 7.62s\n",
      "\n",
      "bestTest = 0.9461077844\n",
      "bestIteration = 9\n",
      "\n",
      "\n",
      "bestTest = 0.9453823237\n",
      "bestIteration = 5\n",
      "\n",
      "\n",
      "bestTest = 0.9433962264\n",
      "bestIteration = 0\n",
      "\n",
      "\n",
      "bestTest = 0.9464285714\n",
      "bestIteration = 3\n",
      "\n",
      "\n",
      "bestTest = 0.9472636816\n",
      "bestIteration = 18\n",
      "\n",
      "\n",
      "bestTest = 0.948\n",
      "bestIteration = 21\n",
      "\n",
      "\n",
      "bestTest = 0.9454905847\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9444444444\n",
      "bestIteration = 7\n",
      "\n",
      "\n",
      "bestTest = 0.9473684211\n",
      "bestIteration = 7\n",
      "\n",
      "\n",
      "bestTest = 0.9473684211\n",
      "bestIteration = 7\n",
      "\n",
      "40:\tloss: 0.9473684\tbest: 0.9512438 (30)\ttotal: 19.3s\tremaining: 3.29s\n",
      "\n",
      "bestTest = 0.9464285714\n",
      "bestIteration = 12\n",
      "\n",
      "\n",
      "bestTest = 0.9454905847\n",
      "bestIteration = 2\n",
      "\n",
      "\n",
      "bestTest = 0.9461077844\n",
      "bestIteration = 23\n",
      "\n",
      "\n",
      "bestTest = 0.9454905847\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9473684211\n",
      "bestIteration = 26\n",
      "\n",
      "\n",
      "bestTest = 0.9454905847\n",
      "bestIteration = 4\n",
      "\n",
      "\n",
      "bestTest = 0.9445544554\n",
      "bestIteration = 2\n",
      "\n",
      "47:\tloss: 0.9445545\tbest: 0.9512438 (30)\ttotal: 23.1s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/4]\n",
      "\n",
      "bestTest = 0.951986755\n",
      "bestIteration = 7\n",
      "\n",
      "Training on fold [1/4]\n",
      "\n",
      "bestTest = 0.9498767461\n",
      "bestIteration = 34\n",
      "\n",
      "Training on fold [2/4]\n",
      "\n",
      "bestTest = 0.9548069022\n",
      "bestIteration = 18\n",
      "\n",
      "Training on fold [3/4]\n",
      "\n",
      "bestTest = 0.9404081633\n",
      "bestIteration = 54\n",
      "\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'random_strength': 2,\n",
       "  'depth': 6,\n",
       "  'l2_leaf_reg': 4,\n",
       "  'learning_rate': 0.4131034482758621},\n",
       " 'cv_results': defaultdict(list,\n",
       "             {'iterations': [0,\n",
       "               1,\n",
       "               2,\n",
       "               3,\n",
       "               4,\n",
       "               5,\n",
       "               6,\n",
       "               7,\n",
       "               8,\n",
       "               9,\n",
       "               10,\n",
       "               11,\n",
       "               12,\n",
       "               13,\n",
       "               14,\n",
       "               15,\n",
       "               16,\n",
       "               17,\n",
       "               18,\n",
       "               19,\n",
       "               20,\n",
       "               21,\n",
       "               22,\n",
       "               23,\n",
       "               24,\n",
       "               25,\n",
       "               26,\n",
       "               27,\n",
       "               28,\n",
       "               29,\n",
       "               30,\n",
       "               31,\n",
       "               32,\n",
       "               33,\n",
       "               34,\n",
       "               35,\n",
       "               36,\n",
       "               37,\n",
       "               38,\n",
       "               39,\n",
       "               40,\n",
       "               41,\n",
       "               42,\n",
       "               43,\n",
       "               44,\n",
       "               45,\n",
       "               46,\n",
       "               47,\n",
       "               48,\n",
       "               49,\n",
       "               50,\n",
       "               51,\n",
       "               52,\n",
       "               53,\n",
       "               54,\n",
       "               55,\n",
       "               56,\n",
       "               57,\n",
       "               58,\n",
       "               59,\n",
       "               60,\n",
       "               61,\n",
       "               62,\n",
       "               63,\n",
       "               64,\n",
       "               65,\n",
       "               66,\n",
       "               67,\n",
       "               68,\n",
       "               69,\n",
       "               70,\n",
       "               71,\n",
       "               72,\n",
       "               73,\n",
       "               74,\n",
       "               75,\n",
       "               76,\n",
       "               77,\n",
       "               78,\n",
       "               79,\n",
       "               80,\n",
       "               81,\n",
       "               82,\n",
       "               83,\n",
       "               84,\n",
       "               85,\n",
       "               86,\n",
       "               87,\n",
       "               88,\n",
       "               89,\n",
       "               90,\n",
       "               91,\n",
       "               92,\n",
       "               93,\n",
       "               94,\n",
       "               95,\n",
       "               96,\n",
       "               97,\n",
       "               98,\n",
       "               99],\n",
       "              'test-F1-mean': [0.9471439216139831,\n",
       "               0.9471439216139831,\n",
       "               0.9469461354360559,\n",
       "               0.9469461354360559,\n",
       "               0.9471439216139831,\n",
       "               0.9473617294743656,\n",
       "               0.9471842935273617,\n",
       "               0.9462036561827405,\n",
       "               0.9458131231119004,\n",
       "               0.9463147338118254,\n",
       "               0.946793666206657,\n",
       "               0.9460289148466989,\n",
       "               0.9458337343046976,\n",
       "               0.9458340738443634,\n",
       "               0.9456376407648316,\n",
       "               0.9454464028180832,\n",
       "               0.9456810244863639,\n",
       "               0.9456810244863639,\n",
       "               0.9457022900453352,\n",
       "               0.9446419511529955,\n",
       "               0.9444219963552739,\n",
       "               0.9452904284308377,\n",
       "               0.9448585791350741,\n",
       "               0.9446666484540946,\n",
       "               0.9444498466031622,\n",
       "               0.9447661306036841,\n",
       "               0.9445784573272233,\n",
       "               0.9446004014930403,\n",
       "               0.9444107828411076,\n",
       "               0.9446287845361957,\n",
       "               0.9448443544967278,\n",
       "               0.9447914630549809,\n",
       "               0.9446256991976969,\n",
       "               0.9445372525584315,\n",
       "               0.945868324349799,\n",
       "               0.9452649127805304,\n",
       "               0.9442511152049299,\n",
       "               0.9442711184090494,\n",
       "               0.9442175800816902,\n",
       "               0.9448250744309459,\n",
       "               0.944582270761372,\n",
       "               0.9441473746200459,\n",
       "               0.9435183264373708,\n",
       "               0.943474848697768,\n",
       "               0.9438561546403907,\n",
       "               0.9442151193144996,\n",
       "               0.943851794144269,\n",
       "               0.9434099016193664,\n",
       "               0.9438440166190698,\n",
       "               0.9438937938457483,\n",
       "               0.9440169343565004,\n",
       "               0.9440165198308652,\n",
       "               0.9438244629045243,\n",
       "               0.9431956169538589,\n",
       "               0.9438477460549874,\n",
       "               0.9424393084805478,\n",
       "               0.9424168050834776,\n",
       "               0.941812380322796,\n",
       "               0.9427847680762679,\n",
       "               0.9425916567796283,\n",
       "               0.9426155038487628,\n",
       "               0.9425888234654758,\n",
       "               0.9428357039261414,\n",
       "               0.9430561433640485,\n",
       "               0.9424486842522711,\n",
       "               0.9415775574604192,\n",
       "               0.9421833927281507,\n",
       "               0.9422257781498862,\n",
       "               0.9414004709171981,\n",
       "               0.9416516185960759,\n",
       "               0.9409006356273264,\n",
       "               0.9413377645373251,\n",
       "               0.9409004757954524,\n",
       "               0.9403210525617688,\n",
       "               0.9417417114121647,\n",
       "               0.9417417114121647,\n",
       "               0.9411376508913383,\n",
       "               0.9411150298731368,\n",
       "               0.9407247689755662,\n",
       "               0.9405354641189387,\n",
       "               0.9405139653737042,\n",
       "               0.9407320079721988,\n",
       "               0.9401067992499257,\n",
       "               0.9405161549740544,\n",
       "               0.9399102454706594,\n",
       "               0.9399102454706594,\n",
       "               0.9400987562906735,\n",
       "               0.9400727583778903,\n",
       "               0.9402910215718392,\n",
       "               0.9407005219813396,\n",
       "               0.9405097666586195,\n",
       "               0.9400765947727163,\n",
       "               0.939910484553131,\n",
       "               0.9397159864605773,\n",
       "               0.9397148477984847,\n",
       "               0.9399556306965005,\n",
       "               0.9401743557444426,\n",
       "               0.9407786899025701,\n",
       "               0.9407786899025701,\n",
       "               0.9403228907818943],\n",
       "              'test-F1-std': [0.005293791931909795,\n",
       "               0.005293791931909795,\n",
       "               0.005074727898764879,\n",
       "               0.005074727898764879,\n",
       "               0.005293791931909795,\n",
       "               0.005474426559435922,\n",
       "               0.005293419765436146,\n",
       "               0.006918132086353273,\n",
       "               0.006692439549933037,\n",
       "               0.00568524938992252,\n",
       "               0.006230394867392459,\n",
       "               0.005573294061099298,\n",
       "               0.005613638488429218,\n",
       "               0.005690091195987994,\n",
       "               0.007050193204649815,\n",
       "               0.007552597364067799,\n",
       "               0.007245098347069686,\n",
       "               0.007245098347069686,\n",
       "               0.008125943747584264,\n",
       "               0.007144967848590411,\n",
       "               0.006859684340313703,\n",
       "               0.008172159532327031,\n",
       "               0.007773519065236444,\n",
       "               0.008097935545813128,\n",
       "               0.007898764382910073,\n",
       "               0.008927462453750349,\n",
       "               0.009366491577608905,\n",
       "               0.008929184895103625,\n",
       "               0.007726617935116819,\n",
       "               0.0070780554989210015,\n",
       "               0.0076348666429260905,\n",
       "               0.008195152442733507,\n",
       "               0.008305775360439084,\n",
       "               0.007951728093687896,\n",
       "               0.00843408370169277,\n",
       "               0.007630680535142918,\n",
       "               0.0074252956736361305,\n",
       "               0.007299177356354757,\n",
       "               0.006962140996516389,\n",
       "               0.006775921395378867,\n",
       "               0.0066954333693796456,\n",
       "               0.006522205374870018,\n",
       "               0.007173404330869391,\n",
       "               0.007047674570104352,\n",
       "               0.0051092220346116565,\n",
       "               0.005173320701436183,\n",
       "               0.005267011769539958,\n",
       "               0.0038101828174485377,\n",
       "               0.003702299799135636,\n",
       "               0.0037442512887303527,\n",
       "               0.0030351201612203397,\n",
       "               0.0028896138390137292,\n",
       "               0.003224181769021143,\n",
       "               0.0025659341576452313,\n",
       "               0.0023285164657708057,\n",
       "               0.0015010250175723882,\n",
       "               0.001967824094734899,\n",
       "               0.002190535015389005,\n",
       "               0.00282368062408009,\n",
       "               0.0032399782504043055,\n",
       "               0.003165643870485308,\n",
       "               0.0027154115044828496,\n",
       "               0.0033108640874370365,\n",
       "               0.0034912550786343967,\n",
       "               0.0033919312781489114,\n",
       "               0.003121588228495345,\n",
       "               0.003604889752551082,\n",
       "               0.002659524240135066,\n",
       "               0.002189867978556844,\n",
       "               0.0029028356493566825,\n",
       "               0.0029391673371927133,\n",
       "               0.003136558177412597,\n",
       "               0.003166978971925536,\n",
       "               0.003129090353680007,\n",
       "               0.0024089043244154957,\n",
       "               0.0024089043244154957,\n",
       "               0.00280742193532089,\n",
       "               0.0025968208052385288,\n",
       "               0.0025472485590576485,\n",
       "               0.002357191992777864,\n",
       "               0.0030230910870612518,\n",
       "               0.0033527400483934554,\n",
       "               0.0037656257569673463,\n",
       "               0.0034452486370145224,\n",
       "               0.0028605418838453635,\n",
       "               0.0028605418838453635,\n",
       "               0.0020667179552252774,\n",
       "               0.002321883675837616,\n",
       "               0.0020186283649348473,\n",
       "               0.0025394994517538615,\n",
       "               0.002199891131799657,\n",
       "               0.0024776115910250026,\n",
       "               0.0028573550510451076,\n",
       "               0.002674862289583067,\n",
       "               0.0027055919665228394,\n",
       "               0.002966643859861444,\n",
       "               0.003050809847066817,\n",
       "               0.003379795127603323,\n",
       "               0.003379795127603323,\n",
       "               0.0031726134655752523],\n",
       "              'train-F1-mean': [0.9481384258885419,\n",
       "               0.9480653685536757,\n",
       "               0.9484438975964491,\n",
       "               0.9487779541289993,\n",
       "               0.9487708269978251,\n",
       "               0.9490684434735676,\n",
       "               0.9494656609386645,\n",
       "               0.9511643804261684,\n",
       "               0.9521469798190676,\n",
       "               0.952650139831919,\n",
       "               0.9539726130406543,\n",
       "               0.9537899671941262,\n",
       "               0.9542087744731909,\n",
       "               0.9544254166761008,\n",
       "               0.9551227538574546,\n",
       "               0.9559834819327934,\n",
       "               0.9571016687721161,\n",
       "               0.9570959613538008,\n",
       "               0.9578545074776113,\n",
       "               0.9584574104531033,\n",
       "               0.9586002926318493,\n",
       "               0.9601001051084964,\n",
       "               0.9605340791875598,\n",
       "               0.9612303455835309,\n",
       "               0.9617078044677114,\n",
       "               0.9625575122016262,\n",
       "               0.9636561737659836,\n",
       "               0.9652973007533125,\n",
       "               0.9659039196938813,\n",
       "               0.9665433865228013,\n",
       "               0.967829216367887,\n",
       "               0.9687306735177181,\n",
       "               0.9692789436538809,\n",
       "               0.9696892109388295,\n",
       "               0.9707087213095836,\n",
       "               0.9720053068671889,\n",
       "               0.9725617860670943,\n",
       "               0.9728480222411642,\n",
       "               0.9739366569227879,\n",
       "               0.9751146463665764,\n",
       "               0.9755869714136608,\n",
       "               0.9769556377191971,\n",
       "               0.9773026394066155,\n",
       "               0.9779803044875202,\n",
       "               0.9788643120889162,\n",
       "               0.9794684994505128,\n",
       "               0.9796812154170396,\n",
       "               0.9810040683867876,\n",
       "               0.981478146679623,\n",
       "               0.9816178437798229,\n",
       "               0.9823031063671395,\n",
       "               0.9824399250796552,\n",
       "               0.9830554842322855,\n",
       "               0.9834704392408802,\n",
       "               0.9839386036815727,\n",
       "               0.9847682391040542,\n",
       "               0.9849024315781756,\n",
       "               0.9857968532775714,\n",
       "               0.9863477066308237,\n",
       "               0.9862847639548715,\n",
       "               0.9869686273727152,\n",
       "               0.9872430652114033,\n",
       "               0.9876595375795509,\n",
       "               0.9881386123876201,\n",
       "               0.9884784270713242,\n",
       "               0.9888205857993133,\n",
       "               0.9887509844451565,\n",
       "               0.9888911700736001,\n",
       "               0.9893043872292222,\n",
       "               0.989577271290288,\n",
       "               0.9900606547964443,\n",
       "               0.990401635653769,\n",
       "               0.9903322595120926,\n",
       "               0.990603902630222,\n",
       "               0.9908796829228965,\n",
       "               0.9910179472789321,\n",
       "               0.9909500729637668,\n",
       "               0.991089728265161,\n",
       "               0.9913602777008899,\n",
       "               0.9919810527209936,\n",
       "               0.9919835328970005,\n",
       "               0.9921202978077891,\n",
       "               0.9923246306225487,\n",
       "               0.9928697570218018,\n",
       "               0.9932102108151988,\n",
       "               0.9932784213248148,\n",
       "               0.9934148044132919,\n",
       "               0.9934139398221035,\n",
       "               0.9938954792236433,\n",
       "               0.9938954789968734,\n",
       "               0.9941008268812511,\n",
       "               0.9941689251430947,\n",
       "               0.9945115235209909,\n",
       "               0.9949928008221312,\n",
       "               0.9951305765099312,\n",
       "               0.9951988996121439,\n",
       "               0.9953347953454736,\n",
       "               0.9953347953454736,\n",
       "               0.9954724579058334,\n",
       "               0.9956792741502412],\n",
       "              'train-F1-std': [0.002362315171766259,\n",
       "               0.002465619424651426,\n",
       "               0.002024403191752881,\n",
       "               0.0018171583206632637,\n",
       "               0.001819266308576997,\n",
       "               0.0016279471034966293,\n",
       "               0.001448163343002965,\n",
       "               0.0022618323573105376,\n",
       "               0.0024183589925392225,\n",
       "               0.0024460154921670716,\n",
       "               0.0024157508121346026,\n",
       "               0.002492880594563376,\n",
       "               0.002590341680444191,\n",
       "               0.0028601469427822885,\n",
       "               0.0019498320615924994,\n",
       "               0.0011639822528067237,\n",
       "               0.0008327911020578408,\n",
       "               0.0010367892957691945,\n",
       "               0.0013500401421435164,\n",
       "               0.0013396509170303123,\n",
       "               0.0012091139976655094,\n",
       "               0.0018829139753620825,\n",
       "               0.0020184704865025475,\n",
       "               0.0012239119176629123,\n",
       "               0.0014262571104189097,\n",
       "               0.0016518528709736965,\n",
       "               0.0020480663548257142,\n",
       "               0.002237262161034227,\n",
       "               0.0021823578107318326,\n",
       "               0.0025315889108146724,\n",
       "               0.002268155904398057,\n",
       "               0.002068476802678967,\n",
       "               0.0023816503195688344,\n",
       "               0.0023650344401226447,\n",
       "               0.002525246957288347,\n",
       "               0.0020951339269484194,\n",
       "               0.0025181331721978407,\n",
       "               0.002447838178173219,\n",
       "               0.002446469761653461,\n",
       "               0.0023343242798901376,\n",
       "               0.0025467529900168044,\n",
       "               0.0018027916096068288,\n",
       "               0.0016146989608938611,\n",
       "               0.0017185824153536093,\n",
       "               0.001347007838109679,\n",
       "               0.001036789287730731,\n",
       "               0.0009590680158564718,\n",
       "               0.001923028456016293,\n",
       "               0.0022783984939685857,\n",
       "               0.00178982415727762,\n",
       "               0.0017052005516656618,\n",
       "               0.001858746490583769,\n",
       "               0.0020938104239874244,\n",
       "               0.0017402620786153686,\n",
       "               0.0018913927793706667,\n",
       "               0.001474865942709385,\n",
       "               0.0018012338835177728,\n",
       "               0.0011504006537480954,\n",
       "               0.0011694613487790732,\n",
       "               0.0011876711817399165,\n",
       "               0.0009673591396929057,\n",
       "               0.0008830799081877308,\n",
       "               0.000543853394698362,\n",
       "               0.0006050424954627109,\n",
       "               0.0005162563797029842,\n",
       "               0.0007649609944733349,\n",
       "               0.0008207904625438353,\n",
       "               0.0008655859370861041,\n",
       "               0.0005123639016290589,\n",
       "               0.0005100162997849521,\n",
       "               0.00047776601272409193,\n",
       "               0.00023042205495907016,\n",
       "               0.0004198284950130528,\n",
       "               0.0007268160388104964,\n",
       "               0.0005677674245750369,\n",
       "               0.0007249178871679157,\n",
       "               0.0006745913264599998,\n",
       "               0.0005722023703206461,\n",
       "               0.0007278845433401987,\n",
       "               0.0007261618307940443,\n",
       "               0.0005658295216898572,\n",
       "               0.0006128646538689863,\n",
       "               0.00038582406479812677,\n",
       "               0.0003905923393753416,\n",
       "               0.00026704306277992813,\n",
       "               0.00047587773571749803,\n",
       "               0.0005916035663612674,\n",
       "               0.0004989104515685986,\n",
       "               0.0004085182216417746,\n",
       "               0.000719701350218706,\n",
       "               0.0006512282826799132,\n",
       "               0.0005187323487590204,\n",
       "               0.00022404172907144977,\n",
       "               0.00013698891840832871,\n",
       "               0.00014042601951949705,\n",
       "               0.00015845108742242796,\n",
       "               0.00022408796477216408,\n",
       "               0.00022408796477216408,\n",
       "               0.00035697155367820087,\n",
       "               0.000263377393068638],\n",
       "              'test-CrossEntropy-mean': [0.10645502036652452,\n",
       "               0.05256535209683893,\n",
       "               0.04245499198196026,\n",
       "               0.03971392794129018,\n",
       "               0.038706860013888345,\n",
       "               0.037922130373554984,\n",
       "               0.03760602780031872,\n",
       "               0.03775616315217743,\n",
       "               0.03736103229892554,\n",
       "               0.037524008441109015,\n",
       "               0.03754305192501057,\n",
       "               0.0375095691197632,\n",
       "               0.03748279466549617,\n",
       "               0.03751730269415768,\n",
       "               0.03760715519312513,\n",
       "               0.03790043225190394,\n",
       "               0.03812312848761277,\n",
       "               0.038131479253673675,\n",
       "               0.03837675991651388,\n",
       "               0.038409074047497466,\n",
       "               0.038396903233773164,\n",
       "               0.03873310142642566,\n",
       "               0.038798890863017924,\n",
       "               0.038787634018798735,\n",
       "               0.0390502397640644,\n",
       "               0.03907663053460399,\n",
       "               0.03921882955460537,\n",
       "               0.03955455987276238,\n",
       "               0.039707131761890425,\n",
       "               0.03991934537999425,\n",
       "               0.03984979445452807,\n",
       "               0.03974066171881826,\n",
       "               0.0399059402666259,\n",
       "               0.03994590576977678,\n",
       "               0.03987414486279283,\n",
       "               0.04009643625135076,\n",
       "               0.04018946625526537,\n",
       "               0.04027104473627949,\n",
       "               0.04030535367450744,\n",
       "               0.040379633323552294,\n",
       "               0.04059448080096304,\n",
       "               0.040777929769130895,\n",
       "               0.040891961293115904,\n",
       "               0.04087497553951431,\n",
       "               0.04087569929689915,\n",
       "               0.041067988340371675,\n",
       "               0.04118328229512644,\n",
       "               0.041188055202012935,\n",
       "               0.04129588064238987,\n",
       "               0.041424197121697794,\n",
       "               0.04152889109103602,\n",
       "               0.04160956566805746,\n",
       "               0.04179679795231827,\n",
       "               0.04170863849610484,\n",
       "               0.04175057226384446,\n",
       "               0.041858635775931366,\n",
       "               0.042031015953267505,\n",
       "               0.042156873264930235,\n",
       "               0.04223206495852267,\n",
       "               0.04231824576108914,\n",
       "               0.04247400729251492,\n",
       "               0.042514062604280825,\n",
       "               0.04266037233747647,\n",
       "               0.042815863258577516,\n",
       "               0.04296264004329431,\n",
       "               0.04319624491003769,\n",
       "               0.043257814902453486,\n",
       "               0.043467441718422054,\n",
       "               0.04369015776635196,\n",
       "               0.04369956375615187,\n",
       "               0.043732684487766765,\n",
       "               0.043847598333900714,\n",
       "               0.04388079634527389,\n",
       "               0.044009107170102556,\n",
       "               0.04407956828410176,\n",
       "               0.04423144627625878,\n",
       "               0.0443042367402673,\n",
       "               0.04437565988556639,\n",
       "               0.044450437911435124,\n",
       "               0.04466586123412352,\n",
       "               0.0446519649898965,\n",
       "               0.044699064963077864,\n",
       "               0.04464590538217504,\n",
       "               0.044637249822065184,\n",
       "               0.04467195542502152,\n",
       "               0.0447623950465476,\n",
       "               0.044819748853719726,\n",
       "               0.04480585703356135,\n",
       "               0.044915330838829724,\n",
       "               0.04492267444688447,\n",
       "               0.044956220376746146,\n",
       "               0.04509351696650788,\n",
       "               0.04516793041406313,\n",
       "               0.045289070323224094,\n",
       "               0.04538180697511915,\n",
       "               0.045533745755153725,\n",
       "               0.045594437367057705,\n",
       "               0.045600681521389116,\n",
       "               0.045667095666360714,\n",
       "               0.045681128379114797],\n",
       "              'test-CrossEntropy-std': [0.002488998892548899,\n",
       "               0.0024247835894056044,\n",
       "               0.0013286829649813542,\n",
       "               0.0013086916101812402,\n",
       "               0.001136304107155746,\n",
       "               0.0010532045094040752,\n",
       "               0.0012294102807088206,\n",
       "               0.001236362286931855,\n",
       "               0.0008648986974855344,\n",
       "               0.0008877781092387528,\n",
       "               0.0011361591398983749,\n",
       "               0.0011828473024052385,\n",
       "               0.0010737808714621124,\n",
       "               0.0010459326086897519,\n",
       "               0.0009782542901674203,\n",
       "               0.0013294157190288807,\n",
       "               0.0012554728475412846,\n",
       "               0.0012765297528228388,\n",
       "               0.0012397872317779278,\n",
       "               0.0011208040708495053,\n",
       "               0.0011278695262077361,\n",
       "               0.0015502848800452184,\n",
       "               0.0016763780019806538,\n",
       "               0.0016869361224956549,\n",
       "               0.001479478237367373,\n",
       "               0.0015409013674833835,\n",
       "               0.0015443717427054385,\n",
       "               0.0017578038470240415,\n",
       "               0.0016678431651702798,\n",
       "               0.001364711524308743,\n",
       "               0.0012702331250551856,\n",
       "               0.0012819000008866173,\n",
       "               0.0011260500030865284,\n",
       "               0.0011718096158406153,\n",
       "               0.0014774657114854364,\n",
       "               0.0011798356145451732,\n",
       "               0.001059128653582732,\n",
       "               0.0011782464869007439,\n",
       "               0.0013661105785299425,\n",
       "               0.0012433370862627025,\n",
       "               0.0013171524122937539,\n",
       "               0.001122894521259377,\n",
       "               0.0011387478257832613,\n",
       "               0.0011276627569150072,\n",
       "               0.0011867930479430469,\n",
       "               0.001081461456283473,\n",
       "               0.0010948359659240531,\n",
       "               0.0012533395402310747,\n",
       "               0.0012338442489544291,\n",
       "               0.0012250652407171134,\n",
       "               0.0011548523647000005,\n",
       "               0.0008914600045105867,\n",
       "               0.0009599485908914873,\n",
       "               0.0009080168381001226,\n",
       "               0.0009671806323252635,\n",
       "               0.0009592358938974456,\n",
       "               0.0011417671986391023,\n",
       "               0.0012636091977686484,\n",
       "               0.0011504472103675831,\n",
       "               0.0011856403139691783,\n",
       "               0.0010457142834545843,\n",
       "               0.000989690521875973,\n",
       "               0.0010506609806029976,\n",
       "               0.0012027985266530557,\n",
       "               0.0012427834714137847,\n",
       "               0.00104126849964036,\n",
       "               0.0010997610988760563,\n",
       "               0.000946681546909233,\n",
       "               0.0007429258776638719,\n",
       "               0.0008532932017797052,\n",
       "               0.0007977277467075836,\n",
       "               0.000927286845757418,\n",
       "               0.0008522501215746662,\n",
       "               0.0008815045739988685,\n",
       "               0.0006701379081474255,\n",
       "               0.0008718273862835782,\n",
       "               0.0010773893804583697,\n",
       "               0.0010267760339223151,\n",
       "               0.0010668822519413503,\n",
       "               0.0010599779937166703,\n",
       "               0.0011569843893273158,\n",
       "               0.0011733996565597839,\n",
       "               0.0011961616163570204,\n",
       "               0.0012345261297589522,\n",
       "               0.0013130503602016258,\n",
       "               0.0013603824624195608,\n",
       "               0.0014273066989204254,\n",
       "               0.0014056255998087818,\n",
       "               0.001454363211094429,\n",
       "               0.0014838402569114142,\n",
       "               0.0014641510395313766,\n",
       "               0.0014943982738398348,\n",
       "               0.0013669776614055316,\n",
       "               0.0013303908943598517,\n",
       "               0.001231373135863664,\n",
       "               0.0011740664569220764,\n",
       "               0.0012150742551407016,\n",
       "               0.0012730357466398609,\n",
       "               0.001306261667263559,\n",
       "               0.0013493457532980874],\n",
       "              'train-CrossEntropy-mean': [0.10609802139828607,\n",
       "               0.05162181992633776,\n",
       "               0.041630897446846206,\n",
       "               0.038079727147176105,\n",
       "               0.036663273906490296,\n",
       "               0.03546538254562123,\n",
       "               0.03477423328414041,\n",
       "               0.033604622224734364,\n",
       "               0.032749572244688205,\n",
       "               0.032381093273098495,\n",
       "               0.03191209580347808,\n",
       "               0.03156401163612739,\n",
       "               0.030994399968480822,\n",
       "               0.030704253120738503,\n",
       "               0.030364193820564333,\n",
       "               0.029861930849329785,\n",
       "               0.02940598634574068,\n",
       "               0.02925327340233641,\n",
       "               0.0287133483066185,\n",
       "               0.028541804096272282,\n",
       "               0.028357230628937587,\n",
       "               0.02782608271560051,\n",
       "               0.02750141043633034,\n",
       "               0.027251301872333128,\n",
       "               0.026802843583688077,\n",
       "               0.026317121697814784,\n",
       "               0.02572434805471928,\n",
       "               0.025073638963672616,\n",
       "               0.02465769114763659,\n",
       "               0.024205111947542247,\n",
       "               0.0235797764184323,\n",
       "               0.02309841300942953,\n",
       "               0.022676384091698993,\n",
       "               0.022232843871861946,\n",
       "               0.021739013476730032,\n",
       "               0.021302629337701044,\n",
       "               0.020902970619468407,\n",
       "               0.020497165654167156,\n",
       "               0.020095661044801743,\n",
       "               0.019753152511561844,\n",
       "               0.019385201296053797,\n",
       "               0.01903523928549816,\n",
       "               0.018645108292927093,\n",
       "               0.018385060823199004,\n",
       "               0.018037960510123352,\n",
       "               0.017767268353481004,\n",
       "               0.01745962748508736,\n",
       "               0.017165196040833372,\n",
       "               0.016849732298221932,\n",
       "               0.01664593441026299,\n",
       "               0.01636330825892367,\n",
       "               0.01607466354138907,\n",
       "               0.015848426740129422,\n",
       "               0.015645202214936357,\n",
       "               0.015437817875971111,\n",
       "               0.015086587164951742,\n",
       "               0.014853440911408146,\n",
       "               0.014626564345393521,\n",
       "               0.014403554941411831,\n",
       "               0.014215922179708157,\n",
       "               0.01402252197464997,\n",
       "               0.013899508992541646,\n",
       "               0.013640997705638487,\n",
       "               0.01342030304107315,\n",
       "               0.01321045324462027,\n",
       "               0.013008579195168308,\n",
       "               0.012910330652227787,\n",
       "               0.012683584689474687,\n",
       "               0.012516908835347885,\n",
       "               0.012337851130722187,\n",
       "               0.012107420975760917,\n",
       "               0.011928304283531567,\n",
       "               0.011783918593046363,\n",
       "               0.011643520987430506,\n",
       "               0.011451237195367794,\n",
       "               0.01136635963396041,\n",
       "               0.011270642369719967,\n",
       "               0.011166395293679195,\n",
       "               0.01098802520542836,\n",
       "               0.01080792412626048,\n",
       "               0.01070973934825513,\n",
       "               0.010593179290450078,\n",
       "               0.010399560252029389,\n",
       "               0.010253364265823338,\n",
       "               0.010138177250079787,\n",
       "               0.010055429877634919,\n",
       "               0.009961809315701191,\n",
       "               0.00987687851828253,\n",
       "               0.009751763714698687,\n",
       "               0.009677253730332616,\n",
       "               0.009561828996375466,\n",
       "               0.009468809745620492,\n",
       "               0.009333815123627076,\n",
       "               0.009224173129890573,\n",
       "               0.009127609335926368,\n",
       "               0.008998633480437855,\n",
       "               0.008901029452101118,\n",
       "               0.008827504482178762,\n",
       "               0.008729024445394765,\n",
       "               0.008590252348529918],\n",
       "              'train-CrossEntropy-std': [0.002097740654130229,\n",
       "               0.0009413680539563864,\n",
       "               0.0008942549832967468,\n",
       "               0.0006301173650089935,\n",
       "               0.0006400740617795199,\n",
       "               0.0004261953286988153,\n",
       "               0.000668326243415578,\n",
       "               0.0007049642669538135,\n",
       "               0.0008463876379998731,\n",
       "               0.0007706939729679072,\n",
       "               0.0007790211713417444,\n",
       "               0.0007570791784193515,\n",
       "               0.0008079491148253622,\n",
       "               0.0007315696049779778,\n",
       "               0.0005850360667055634,\n",
       "               0.0005992294094024208,\n",
       "               0.0005174463323820001,\n",
       "               0.0005232208085529671,\n",
       "               0.0005705466233301285,\n",
       "               0.0005349860723630353,\n",
       "               0.0005810049723059241,\n",
       "               0.0006256039910252668,\n",
       "               0.0004518018997898344,\n",
       "               0.0003972063344212197,\n",
       "               0.00038045045814913317,\n",
       "               0.0007161650220504698,\n",
       "               0.0007808987188229526,\n",
       "               0.0009037723008989252,\n",
       "               0.0009671088116360641,\n",
       "               0.000778577347222544,\n",
       "               0.0006828564173833602,\n",
       "               0.0006623004778022409,\n",
       "               0.0007385989649431543,\n",
       "               0.0006552489704225815,\n",
       "               0.0005725715968566664,\n",
       "               0.0006139451156712384,\n",
       "               0.0005009475917323974,\n",
       "               0.0006314071730869361,\n",
       "               0.0006587494932842122,\n",
       "               0.0006703997962499411,\n",
       "               0.000697828418300091,\n",
       "               0.0006584491843414644,\n",
       "               0.0005717512951565306,\n",
       "               0.0005712994882464988,\n",
       "               0.0005495643269791441,\n",
       "               0.0005027842739182943,\n",
       "               0.0006075054408695898,\n",
       "               0.0006613722172720082,\n",
       "               0.0006702783135984483,\n",
       "               0.0006666770983796628,\n",
       "               0.0006025784237941316,\n",
       "               0.0005359320159287569,\n",
       "               0.0005774897534992562,\n",
       "               0.0006380938839203973,\n",
       "               0.0007076920110661496,\n",
       "               0.0007220067747973612,\n",
       "               0.0007061497531217781,\n",
       "               0.0006337040066287835,\n",
       "               0.0006262599130135669,\n",
       "               0.0004876671751006616,\n",
       "               0.0005141168235155838,\n",
       "               0.00044881550602786726,\n",
       "               0.0003911409907097153,\n",
       "               0.0003637507786144843,\n",
       "               0.0003774139793364077,\n",
       "               0.00031982534531810775,\n",
       "               0.00036420540901756953,\n",
       "               0.00043026340507931705,\n",
       "               0.00037475467995480317,\n",
       "               0.0004365412393457422,\n",
       "               0.0004936523907229162,\n",
       "               0.0004341068274129565,\n",
       "               0.00040331823096468624,\n",
       "               0.0004933774541851291,\n",
       "               0.0004561229396962275,\n",
       "               0.00048783483066908417,\n",
       "               0.0005036122236577792,\n",
       "               0.0004566781298499448,\n",
       "               0.00045264291135126155,\n",
       "               0.0005130727254335362,\n",
       "               0.000527084589613786,\n",
       "               0.0005692983532661416,\n",
       "               0.0005729355938165684,\n",
       "               0.0005983124531355706,\n",
       "               0.0006194222187828096,\n",
       "               0.000654868470482721,\n",
       "               0.0006628314355674546,\n",
       "               0.0006764020674854169,\n",
       "               0.0006569599863120992,\n",
       "               0.0007172791975592861,\n",
       "               0.0006990916405771353,\n",
       "               0.0007028445372918178,\n",
       "               0.0006934115196837267,\n",
       "               0.0006454214038770625,\n",
       "               0.0006154121312974463,\n",
       "               0.0005515500701119109,\n",
       "               0.0005623340011820053,\n",
       "               0.00060606206018623,\n",
       "               0.0006015727194969874,\n",
       "               0.0006226191657483669]})}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cat_model = CatBoostClassifier(iterations=100, loss_function=\"CrossEntropy\", eval_metric='F1', verbose=0, thread_count=8)\n",
    "params = {'learning_rate': np.linspace(0.38, 0.5, num=30), \n",
    "          'depth': [5,6,7], \n",
    "          'l2_leaf_reg': [2,3,4], \n",
    "          'random_strength': [1, 1.2, 2]\n",
    "         }\n",
    "cat_model.randomized_search(params, X=features_train, y=target_train,\n",
    "                            partition_random_seed=12479, verbose=10, plot=True, shuffle=True, stratified=True, \n",
    "                            cv=4, n_iter=48\n",
    "                           );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Комментарий студента:</b> Скриншот последнего результата ↓\n",
    "</div>"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn': {'F1': 0.9671322925225966, 'CrossEntropy': 0.023521115064239637}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'iterations': 100,\n",
       " 'loss_function': 'CrossEntropy',\n",
       " 'thread_count': 8,\n",
       " 'verbose': 0,\n",
       " 'eval_metric': 'F1',\n",
       " 'random_strength': 2,\n",
       " 'depth': 6,\n",
       " 'l2_leaf_reg': 4,\n",
       " 'learning_rate': 0.4131034482758621}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cat_model.get_best_score())\n",
    "cat_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:44:22'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime(\"%d.%m.%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catboost cross val score: 0.9478 (+/- 0.01601)\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cat_model.fit(X=features_train, y=target_train)\n",
    "# predicted_cat = cat_model.predict(features_train)\n",
    "# print(f\"\\nf1 on train: {f1_score(target_train, predicted_cat):3.2f}\\n\")\n",
    "scores = cross_val_score(cat_model, features_train, target_train, cv=7, scoring='f1')\n",
    "print(\"Catboost cross val score: %0.4f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:44:24'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime(\"%d.%m.%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:48:00'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "[LibSVM]Wall time: 6.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skysh\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_model = SVC(shrinking=True, probability=False, tol=0.0005, cache_size=300, class_weight='balanced', \n",
    "                verbose=True, max_iter=300, break_ties=False, random_state=16841)\n",
    "\n",
    "params = dict(C=np.linspace(0.54, 0.58, 15),\n",
    "              kernel=['linear', 'poly'], #, 'rbf', 'sigmoid'\n",
    "              degree=[2,3,4], \n",
    "              gamma=['scale','auto'], \n",
    "              coef0=np.linspace(0.22, 0.34, 15), \n",
    "              decision_function_shape=['ovo', 'ovr']\n",
    "             )\n",
    "grid = RandomizedSearchCV(svc_model, params, verbose=3, scoring='f1', cv=4, n_jobs=8, n_iter=40)\n",
    "grid.fit(features_train, target_train)\n",
    "best_svc = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'gamma': 'auto', 'degree': 3, 'decision_function_shape': 'ovr', 'coef0': 0.28, 'C': 0.5457142857142857} \n",
      "\n",
      "0.8883011517286199 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_,'\\n')\n",
    "print(grid.best_score_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:48:06'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:49:46'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "-- Epoch 1\n",
      "Norm: 619.14, NNZs: 6, Bias: 80.492439, T: 16472, Avg. loss: 80.769869\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 506.70, NNZs: 6, Bias: 76.876361, T: 32944, Avg. loss: 47.193810\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 430.59, NNZs: 6, Bias: 70.312084, T: 49416, Avg. loss: 37.274806\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 372.49, NNZs: 6, Bias: 64.778749, T: 65888, Avg. loss: 28.482310\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 324.93, NNZs: 6, Bias: 61.309252, T: 82360, Avg. loss: 22.528128\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 284.96, NNZs: 6, Bias: 58.736899, T: 98832, Avg. loss: 19.308343\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 250.62, NNZs: 6, Bias: 56.455439, T: 115304, Avg. loss: 15.181316\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sgd_model = SGDClassifier(fit_intercept=True, max_iter=700, tol=0.00001, shuffle=True, verbose=2, \n",
    "                          random_state=48253, class_weight='balanced', warm_start=False)\n",
    "\n",
    "params = dict(loss=['modified_huber', 'perceptron'],   #  'hinge', 'squared_hinge', \n",
    "              penalty=['l2'],    #, 'elasticnet'\n",
    "              alpha=[0.000001, 0.00001], \n",
    "              early_stopping=[True], \n",
    "              n_iter_no_change=[4,5,6,7,10,20], \n",
    "              learning_rate=['invscaling', 'adaptive'],   #'optimal', 'constant', \n",
    "              eta0=[5, 9, 13, 50], \n",
    "              power_t=[0.5, 0.9, 1.1], \n",
    "              validation_fraction=[0.08, 0.1, 0.1125], \n",
    "              average=[False, 5, 9]\n",
    "             )\n",
    "grid = RandomizedSearchCV(sgd_model, params, verbose=1, scoring='f1', cv=5, n_jobs=8, n_iter=96)\n",
    "grid.fit(features_train, target_train)\n",
    "best_sgd = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation_fraction': 0.1125, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 6, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'eta0': 13, 'early_stopping': True, 'average': False, 'alpha': 1e-06} \n",
      "\n",
      "0.9392897524749533 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_,'\\n')\n",
    "print(grid.best_score_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.08.2022 00:50:02'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.today().strftime('%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель метрики получили для CatBoost, поэтому проверим эту модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost's final test F1: 0.940\n",
      "\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predicted_test_lr = best_lr.predict(features_test)\n",
    "# print(f\"Linear reg's final test F1: {f1_score(target_test, predicted_test_lr):3.3f}\\n\")\n",
    "\n",
    "predicted_test_cat = cat_model.predict(features_test)\n",
    "print(f\"CatBoost's final test F1: {f1_score(target_test, predicted_test_cat):3.3f}\\n\")\n",
    "\n",
    "# predicted_test_svc = best_svc.predict(features_test)\n",
    "# print(f\"SVC's final test F1: {f1_score(target_test, predicted_test_svc):3.3f}\\n\")\n",
    "\n",
    "# predicted_test_sgd = best_sgd.predict(features_test)\n",
    "# print(f\"SGDClassifier's final test F1: {f1_score(target_test, predicted_test_sgd):3.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.1846 (+/- 0.00004)\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='constant', #'stratified'\n",
    "                        constant=1\n",
    "                       )\n",
    "scores = cross_val_score(dummy, features_test, target_test, scoring='f1')\n",
    "print(\"Dummy classifier score: %0.4f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на адекватность пройдена: результат dummy-классификатора значительно хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяя вместо DistilBERT уже обученную модель toxic-BERT, удалось повысить показатель метрики *F1* с 0.68 до **0.94**. Лучшей моделью снова оказалась CatBoost. Но линейная регрессия и SGD не сильно отстают, к тому же линейная регрессия обучается быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 55,
    "start_time": "2022-08-21T15:29:37.738Z"
   },
   {
    "duration": 148126,
    "start_time": "2022-08-21T15:29:41.281Z"
   },
   {
    "duration": 267,
    "start_time": "2022-08-21T15:34:41.121Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-21T15:34:50.056Z"
   },
   {
    "duration": 89,
    "start_time": "2022-08-21T15:34:57.610Z"
   },
   {
    "duration": 3347,
    "start_time": "2022-08-21T15:35:05.708Z"
   },
   {
    "duration": 21,
    "start_time": "2022-08-21T15:35:23.008Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-21T15:35:49.999Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
